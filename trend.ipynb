{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit1e0af8580e2d4796bb7998300dc6c721",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import time\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#%matplotlib inline\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "py.init_notebook_mode()\n",
    "    \n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Filter constants for states in US\n",
    "STATES = ['Alabama', 'AL', 'Alaska', 'AK', 'American Samoa', 'AS', 'Arizona', 'AZ', 'Arkansas', 'AR', 'California', 'CA', 'Colorado', 'CO', 'Connecticut', 'CT', 'Delaware', 'DE', 'District of Columbia', 'DC', 'Federated States of Micronesia', 'FM', 'Florida', 'FL', 'Georgia', 'GA', 'Guam', 'GU', 'Hawaii', 'HI', 'Idaho', 'ID', 'Illinois', 'IL', 'Indiana', 'IN', 'Iowa', 'IA', 'Kansas', 'KS', 'Kentucky', 'KY', 'Louisiana', 'LA', 'Maine', 'ME', 'Marshall Islands', 'MH', 'Maryland', 'MD', 'Massachusetts', 'MA', 'Michigan', 'MI', 'Minnesota', 'MN', 'Mississippi', 'MS', 'Missouri', 'MO', 'Montana', 'MT', 'Nebraska', 'NE', 'Nevada', 'NV', 'New Hampshire', 'NH', 'New Jersey', 'NJ', 'New Mexico', 'NM', 'New York', 'NY', 'North Carolina', 'NC', 'North Dakota', 'ND', 'Northern Mariana Islands', 'MP', 'Ohio', 'OH', 'Oklahoma', 'OK', 'Oregon', 'OR', 'Palau', 'PW', 'Pennsylvania', 'PA', 'Puerto Rico', 'PR', 'Rhode Island', 'RI', 'South Carolina', 'SC', 'South Dakota', 'SD', 'Tennessee', 'TN', 'Texas', 'TX', 'Utah', 'UT', 'Vermont', 'VT', 'Virgin Islands', 'VI', 'Virginia', 'VA', 'Washington', 'WA', 'West Virginia', 'WV', 'Wisconsin', 'WI', 'Wyoming', 'WY']\n",
    "STATE_DICT = dict(itertools.zip_longest(*[iter(STATES)] * 2, fillvalue=\"\"))\n",
    "INV_STATE_DICT = dict((v,k) for k,v in STATE_DICT.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"Num of '#JeffreeStarApproved' mentions\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Num of '#JeffreeStarApproved' mentions\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-af19671a1e5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m     fig.add_trace(go.Scatter(\n\u001b[0;32m     39\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_series\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Num of '{}' mentions\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRACK_WORDS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'polarity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Neural\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         opacity=0.8), row=1, col=1)   \n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Num of '#JeffreeStarApproved' mentions\""
     ]
    }
   ],
   "source": [
    "'''\n",
    "This complex plot shows the latest Twitter data within 20 mins and will automatically update.\n",
    "'''\n",
    "while True:\n",
    "    clear_output()\n",
    "    db_connection = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    passwd=\"gaurav\",\n",
    "    database=\"TwitterDB\",\n",
    "    charset = 'utf8'\n",
    "    )\n",
    "    # Load data from MySQL\n",
    "    timenow = (datetime.datetime.utcnow() - datetime.timedelta(hours=0, minutes=20)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    query = \"SELECT id_str, text, created_at, polarity, user_location FROM {} WHERE created_at >= '{}' \" \\\n",
    "                     .format(settings.TABLE_NAME, timenow)\n",
    "    df = pd.read_sql(query, con=db_connection)\n",
    "    # UTC for date time at default\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        column_widths=[1, 0.4],\n",
    "        row_heights=[0.6, 0.4],\n",
    "        specs=[[{\"type\": \"scatter\", \"rowspan\": 2}, {\"type\": \"choropleth\"}],\n",
    "               [            None                    , {\"type\": \"bar\"}]]\n",
    "        )\n",
    "\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Plot the Line Chart\n",
    "    '''\n",
    "    # Clean and transform data to enable time series\n",
    "    result = df.groupby([pd.Grouper(key='created_at', freq='2s'), 'polarity']).count().unstack(fill_value=0).stack().reset_index()\n",
    "    result = result.rename(columns={\"id_str\": \"Num of '{}' mentions\".format(settings.TRACK_WORDS[0]), \"created_at\":\"Time in UTC\"})  \n",
    "    time_series = result[\"Time in UTC\"][result['polarity']==0].reset_index(drop=True)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=time_series,\n",
    "        y=result[\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==0].reset_index(drop=True),\n",
    "        name=\"Neural\",\n",
    "        opacity=0.8), row=1, col=1)   \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=time_series,\n",
    "        y=result[\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==-1].reset_index(drop=True),\n",
    "        name=\"Negative\",\n",
    "        opacity=0.8), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=time_series,\n",
    "        y=result[\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==1].reset_index(drop=True),\n",
    "        name=\"Positive\",\n",
    "        opacity=0.8), row=1, col=1)\n",
    "    \n",
    "    '''\n",
    "    Plot the Bar Chart\n",
    "    '''\n",
    "    content = ' '.join(df[\"text\"])\n",
    "    content = re.sub(r\"http\\S+\", \"\", content)\n",
    "    content = content.replace('RT ', ' ').replace('&amp;', 'and')\n",
    "    content = re.sub('[^A-Za-z0-9]+', ' ', content)\n",
    "    content = content.lower()\n",
    "\n",
    "    tokenized_word = word_tokenize(content)\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    filtered_sent=[]\n",
    "    for w in tokenized_word:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(w)\n",
    "    fdist = FreqDist(filtered_sent)\n",
    "    fd = pd.DataFrame(fdist.most_common(10), columns = [\"Word\",\"Frequency\"]).drop([0]).reindex()\n",
    "    \n",
    "    # Plot Bar chart   \n",
    "    fig.add_trace(go.Bar(x=fd[\"Word\"], y=fd[\"Frequency\"], name=\"Freq Dist\"), row=2, col=2)\n",
    "    # 59, 89, 152\n",
    "    fig.update_traces(marker_color='rgb(59, 89, 152)', marker_line_color='rgb(8,48,107)', \\\n",
    "            marker_line_width=0.5, opacity=0.7, row=2, col=2)\n",
    "    \n",
    "    '''\n",
    "    Plot the Geo-Distribution\n",
    "    '''\n",
    "    is_in_US=[]\n",
    "    geo = df[['user_location']]\n",
    "    df = df.fillna(\" \")\n",
    "    for x in df['user_location']:\n",
    "        check = False\n",
    "        for s in STATES:\n",
    "            if s in x:\n",
    "                is_in_US.append(STATE_DICT[s] if s in STATE_DICT else s)\n",
    "                check = True\n",
    "                break\n",
    "        if not check:\n",
    "            is_in_US.append(None)\n",
    "\n",
    "    geo_dist = pd.DataFrame(is_in_US, columns=['State']).dropna().reset_index()\n",
    "    geo_dist = geo_dist.groupby('State').count().rename(columns={\"index\": \"Number\"}) \\\n",
    "            .sort_values(by=['Number'], ascending=False).reset_index()\n",
    "    geo_dist[\"Log Num\"] = geo_dist[\"Number\"].apply(lambda x: math.log(x, 2))\n",
    "\n",
    "\n",
    "    geo_dist['Full State Name'] = geo_dist['State'].apply(lambda x: INV_STATE_DICT[x])\n",
    "    geo_dist['text'] = geo_dist['Full State Name'] + '<br>' + 'Num: ' + geo_dist['Number'].astype(str)\n",
    "    fig.add_trace(go.Choropleth(\n",
    "        locations=geo_dist['State'], # Spatial coordinates\n",
    "        z = geo_dist['Log Num'].astype(float), # Data to be color-coded\n",
    "        locationmode = 'USA-states', # set of locations match entries in `locations`\n",
    "        colorscale = \"Blues\",\n",
    "        text=geo_dist['text'], # hover text\n",
    "        showscale=False,\n",
    "        geo = 'geo'\n",
    "        ),\n",
    "        row=1, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title_text= \"Real-time tracking '{}' mentions on Twitter {} UTC\".format(settings.TRACK_WORDS[0] ,datetime.datetime.utcnow().strftime('%m-%d %H:%M')),\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "        ),\n",
    "        template=\"plotly_dark\",\n",
    "        margin=dict(r=20, t=50, b=50, l=20),\n",
    "        annotations=[\n",
    "            go.layout.Annotation(\n",
    "                text=\"Source: Twitter\",\n",
    "                showarrow=False,\n",
    "                xref=\"paper\",\n",
    "                yref=\"paper\",\n",
    "                x=0,\n",
    "                y=0)\n",
    "        ],\n",
    "        showlegend=False,\n",
    "        xaxis_rangeslider_visible=True\n",
    "    )\n",
    "         \n",
    "    fig.show()\n",
    "    \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}